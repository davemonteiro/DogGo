{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DogGo - This Jupyter notebook contains code to generate the datasets and files required by DogGo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "\n",
    "import folium\n",
    "from folium import FeatureGroup, LayerControl, Map, Marker\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assemble dog breed, size, exercise reqs csv\n",
    "page = requests.get('http://dogtime.com/dog-breeds')\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "soup_breeds = str(soup.find_all(class_='search-results-list'))\n",
    "dogs = []\n",
    "\n",
    "while 'dog-breeds' in soup_breeds:\n",
    "    soup_breeds = soup_breeds[soup_breeds.index('dog-breeds')+1:]\n",
    "    slash = soup_breeds.index('/')\n",
    "    greater = soup_breeds.index('>')\n",
    "    name = soup_breeds[slash+1:greater-1]\n",
    "    dogs.append(name)\n",
    "\n",
    "#List of dogs\n",
    "dogs = list(dict.fromkeys(dogs))\n",
    "\n",
    "#Mutt is a bit arbitrary, users should pick a more specific breed or a preset\n",
    "dogs.remove('mutt')\n",
    "\n",
    "#Run next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape exercise levels and dog sizes from Dogtime.com\n",
    "exercise_levels = []\n",
    "heights = []\n",
    "\n",
    "for dog in dogs:\n",
    "    time.sleep(2)\n",
    "    print(dog)\n",
    "    url = 'http://dogtime.com/dog-breeds/' + dog\n",
    "    page = requests.get(str(url).rstrip())\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    soup_string = str(soup)\n",
    "    exercise_levels.append(int(soup_string[80+soup_string.index('Exercise Needs'):81+soup_string.index('Exercise Needs')]))\n",
    "    \n",
    "    if ('Height:<') in soup_string:\n",
    "        soup_string = soup_string[soup_string.index('Height:<'):]\n",
    "        heights.append(soup_string[13:soup_string.index('</div><div')])\n",
    "    else:\n",
    "        heights.append('0')\n",
    "        \n",
    "#Run next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the dog heights to obtain an estimate of height in inches\n",
    "\n",
    "#Some formats:\n",
    "#X to Y inches\n",
    "#A feet to A feet, B inches\n",
    "#Up to X inches\n",
    "\n",
    "heights2 = []\n",
    "for height in heights:\n",
    "    height = height.lower()\n",
    "    substrings = ['Â½','tall at the shoulder', ',', 'inches', 'inch', 'from']\n",
    "    for string in substrings:\n",
    "        height = height.replace(string, '')\n",
    "    height = height.replace('1 foot', '12')\n",
    "    height = height.replace('2 feet', '24')\n",
    "    heights2.append(height.split(' '))\n",
    "    \n",
    "final_heights = []\n",
    "for string_list in heights2:\n",
    "    for i in range(-1 + len(string_list)):\n",
    "        if string_list[i].isdigit():\n",
    "            if string_list[i+1].isdigit():\n",
    "                final_heights.append(int(string_list[i]) + int(string_list[i+1]))\n",
    "                break\n",
    "            else:\n",
    "                final_heights.append(int(string_list[i]))\n",
    "                break\n",
    "        \n",
    "#Run next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save .csv of dog data\n",
    "dog_df = ['Small/Low Energy Dog','Medium Size/Energy Dog','Big/High Energy Dog'] + dogs\n",
    "\n",
    "#Preset selections\n",
    "exercise_levels_df = [2,3,4] + exercise_levels\n",
    "heights_df = [10,16,22] + final_heights\n",
    "\n",
    "dog_df = pd.DataFrame({'Name': dog_df, 'Exercise-Needs': exercise_levels_df, 'Height': heights_df})\n",
    "dog_df.to_csv('data/dogbreeds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assemble park csv - takes a while\n",
    "\n",
    "#From Boston Parks and Recreation\n",
    "#https://www.boston.gov/departments/parks-and-recreation/popular-playgrounds-and-parks-boston\n",
    "#Column 1 = Name, Column 2 = Address\n",
    "\n",
    "park_df = pd.read_csv('data/parks.csv')\n",
    "lats = []\n",
    "lons = []\n",
    "\n",
    "#Attempt to find lat and lon of these Boston parks\n",
    "#1st try match by name, then by address\n",
    "#Manually removed parks that did not match\n",
    "for row in park_df.itertuples():\n",
    "    time.sleep(2)\n",
    "    park_name = getattr(row,'Name') + ' Boston'\n",
    "    try:\n",
    "        park_coords = ox.geo_utils.geocode(park_name)\n",
    "        lats.append(park_coords[0])\n",
    "        lons.append(park_coords[1])\n",
    "    except:\n",
    "        \n",
    "        try:\n",
    "            park_coords = ox.geo_utils.geocode(getattr(row,'Address') + ' Boston')\n",
    "            lats.append(park_coords[0])\n",
    "            lons.append(park_coords[1])\n",
    "        except:\n",
    "            #print('Not matched:')\n",
    "            #print(park_name)\n",
    "            lats.append(0)\n",
    "            lons.append(0)\n",
    "            continue\n",
    "\n",
    "#Make new columns in df and save\n",
    "park_df['lat'] = lats\n",
    "park_df['lon'] = lons\n",
    "park_df.to_csv('data/parks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assemble tree csv\n",
    "\n",
    "#Boston from https://data.boston.gov/dataset/trees (200k trees)\n",
    "#Brookline from http://data.brooklinema.gov/datasets/09a978fa7ffc46d7b6ca06adfddecdf8_0 (11k trees)\n",
    "\n",
    "#tree_df = pd.read_csv('data/boston_trees.csv')\n",
    "tree_df = pd.read_csv('data/brookline_trees.csv')\n",
    "\n",
    "#Get bounding box coordinates\n",
    "xmax = tree_df['X'].max() #East\n",
    "xmin = tree_df['X'].min() #West\n",
    "ymax = tree_df['Y'].max() #North\n",
    "ymin = tree_df['Y'].min() #South\n",
    "\n",
    "H = ox.graph_from_bbox(ymax, ymin, xmax, xmin, network_type='walk')\n",
    "\n",
    "node_treecount = {}\n",
    "for row in tree_df.itertuples():\n",
    "    lon = getattr(row, 'X')\n",
    "    lat = getattr(row, 'Y')\n",
    "    \n",
    "    node = ox.get_nearest_node(H, (lat, lon))\n",
    "    if not node in node_treecount:\n",
    "        node_treecount[int(node)] = 1\n",
    "    else:\n",
    "        node_treecount[int(node)] += 1\n",
    "        \n",
    "node_tree_df = pd.DataFrame.from_dict(node_treecount, orient='index', columns=['trees'])\n",
    "#node_tree_df.to_csv('data/boston_nodetrees.csv')\n",
    "node_tree_df.to_csv('data/brookline_nodetrees.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Boston and Brookline datasets generated, merge them\n",
    "boston_nodetree = pd.read_csv('data/boston_nodetrees.csv')\n",
    "brookline_nodetree = pd.read_csv('data/brookline_nodetrees.csv')\n",
    "\n",
    "boston_tree_dict = dict(zip(boston_nodetree.node, boston_nodetree.trees))\n",
    "brookline_tree_dict = dict(zip(brookline_nodetree.node, brookline_nodetree.trees))\n",
    "\n",
    "combined_tree_dict = dict(Counter(boston_tree_dict)+Counter(brookline_tree_dict))\n",
    "combined_tree_df = pd.DataFrame.from_dict(combined_tree_dict, orient='index', columns=['trees'])\n",
    "combined_tree_df.to_csv('data/combined_nodetrees.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This cell takes a few minutes\n",
    "#Generate graph given bounding box coordinates\n",
    "#This takes (North, South, East, West) lats/lons\n",
    "\n",
    "xmax = -71.02 #East\n",
    "xmin = -71.18 #West\n",
    "ymax = 42.38  #North\n",
    "ymin = 42.32  #South\n",
    "\n",
    "G = ox.graph_from_bbox(ymax, ymin, xmax, xmin, network_type='walk')\n",
    "\n",
    "#Get nodes and edges in dataframes\n",
    "gdf_nodes, gdf_edges = ox.graph_to_gdfs(G)\n",
    "\n",
    "#Modify gdf variables\n",
    "gdf_nodes.drop(columns=['ref', 'highway','osmid','geometry'], inplace=True)\n",
    "gdf_edges.drop(columns=['maxspeed','osmid','tunnel','ref','name','service','junction','bridge','access','area','geometry','oneway','lanes'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot graph\n",
    "fig, ax = ox.plot_graph_routes(G, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign tree and safety values to edges\n",
    "combined_tree_df = pd.read_csv('data/combined_nodetrees.csv')\n",
    "combined_tree_df.set_index('node', inplace=True)\n",
    "gdf_nodes = gdf_nodes.join(combined_tree_df)\n",
    "gdf_nodes['trees'].fillna(0, inplace=True)\n",
    "\n",
    "#Trees\n",
    "gdf_edges['trees'] = [int(0.5*(gdf_nodes.loc[u]['trees'] + gdf_nodes.loc[v]['trees'])) for u,v in zip(gdf_edges['u'], gdf_edges['v'])]\n",
    "\n",
    "#Safety\n",
    "gdf_edges['safety'] = np.where(gdf_edges['highway']=='residential', 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_counts = {}\n",
    "road_safety = {}\n",
    "\n",
    "#Set each edge's tree weight as the average of the tree weights of the edge's vertices\n",
    "for row in gdf_edges.itertuples():\n",
    "    u = getattr(row,'u')\n",
    "    v = getattr(row,'v')\n",
    "    key = getattr(row, 'key')\n",
    "    tree_count = getattr(row, 'trees')\n",
    "    safety_score = getattr(row, 'safety')\n",
    "\n",
    "    tree_counts[(u,v,key)] = tree_count\n",
    "    road_safety[(u,v,key)] = safety_score\n",
    "    \n",
    "nx.set_edge_attributes(G, tree_counts, 'numtrees')\n",
    "nx.set_edge_attributes(G, road_safety, 'safety')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save graph and dataframes to pickle\n",
    "#ox.save_graphml(G, filename='greater_boston')\n",
    "#gdf_nodes.to_pickle('data/nodes.pkl',protocol=4)\n",
    "#gdf_edges.to_pickle('data/edges.pkl',protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate histogram of street lengths\n",
    "\n",
    "#Residential streets only\n",
    "gdf_edges_res = gdf_edges.loc[gdf_edges['highway'] == 'residential']\n",
    "\n",
    "_ = plt.hist(gdf_edges_res['length'].values.tolist(),bins='auto')\n",
    "plt.title('Lengths of road segments in Greater Boston', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=16)\n",
    "plt.xlabel('Length (m)',fontsize=16)\n",
    "plt.xlim([-5, 300])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate histogram of trees/street\n",
    "\n",
    "_ = plt.hist(gdf_edges['trees'].tolist(), np.arange(1,50))\n",
    "plt.title('Trees/street in Boston', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=16)\n",
    "plt.xlabel('Number of trees/street',fontsize=16)\n",
    "plt.xlim([0,50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load graph, nodes, and edges (if necessary)\n",
    "#G = ox.load_graphml(filename='greater_boston')\n",
    "#gdf_nodes = pd.read_pickle('data/nodes.pkl')\n",
    "#gdf_edges = pd.read_pickle('data/edges.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate a heatmap of Boston trees\n",
    "\n",
    "for_map = pd.read_csv('data/boston_trees.csv')\n",
    "\n",
    "hm_base = folium.Map(location=[42.3, -71.1], zoom_start=11)\n",
    "hm_content = HeatMap(list(zip(for_map.Y.values, for_map.X.values)),min_opacity=1,radius=4,blur=5)\n",
    "\n",
    "hm_base.add_child(hm_content)\n",
    "#hm_base.save('bostonheatmap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate a heatmap of Brookline trees\n",
    "\n",
    "for_map = pd.read_csv('data/brookline_trees.csv')\n",
    "\n",
    "hm_base = folium.Map(location=[42.3, -71.1], zoom_start=11)\n",
    "hm_content = HeatMap(list(zip(for_map.Y.values, for_map.X.values)),min_opacity=1,radius=4,blur=5)\n",
    "\n",
    "hm_base.add_child(hm_content)\n",
    "#hm_base.save('brooklineheatmap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a map of street-quietness in Boston\n",
    "\n",
    "edges = gdf_edges.loc[gdf_edges['safety'] == 5]\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for row in edges.itertuples():\n",
    "    for node in [gdf_nodes.loc[getattr(row,'u')]]:\n",
    "        xs.append(node['x'])\n",
    "        ys.append(node['y'])\n",
    "    \n",
    "edges.insert(len(edges.columns), 'x', xs)\n",
    "edges.insert(len(edges.columns), 'y', ys)\n",
    "\n",
    "hm_base = folium.Map(location=[42.3, -71.1], zoom_start=11)\n",
    "hm_content = HeatMap(list(zip(edges.y.values, edges.x.values)),min_opacity=1,radius=4,blur=5)\n",
    "\n",
    "hm_base.add_child(hm_content)\n",
    "#hm_base.save('quiet_streets.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dog-treets]",
   "language": "python",
   "name": "conda-env-dog-treets-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
